

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>twocan.RegEstimator &mdash; Twocan 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=01f34227"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="twocan.IFProcessor" href="twocan.IFProcessor.html" />
    <link rel="prev" title="API Reference" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Twocan
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quickstart Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../concepts.html">Core Concepts</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/index.html">Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#core-classes">Core Classes</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">twocan.RegEstimator</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#twocan.RegEstimator"><code class="docutils literal notranslate"><span class="pre">RegEstimator</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#preprocessors">Preprocessors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#optimization-functions">Optimization Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#callbacks">Callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#utilities">Utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#plotting">Plotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#module-twocan">Complete API</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Twocan</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">API Reference</a></li>
      <li class="breadcrumb-item active">twocan.RegEstimator</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/api/generated/twocan.RegEstimator.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="twocan-regestimator">
<h1>twocan.RegEstimator<a class="headerlink" href="#twocan-regestimator" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="twocan.RegEstimator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">twocan.</span></span><span class="sig-name descname"><span class="pre">RegEstimator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">registration_max_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">registration_percentile</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.9</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/twocan/base.html#RegEstimator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#twocan.RegEstimator" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html#sklearn.base.TransformerMixin" title="(in scikit-learn v1.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TransformerMixin</span></code></a>, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="(in scikit-learn v1.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseEstimator</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/abc.html#abc.ABC" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></a></p>
<p>A scikit-learn compatible estimator for multimodal image registration.</p>
<p>This class implements feature-based image registration using OpenCV’s ORB
(Oriented FAST and Rotated BRIEF) detector and a partial affine transformation
model. It follows scikit-learn’s estimator API with fit, transform, and
fit_transform methods, making it easy to integrate into machine learning pipelines.</p>
<p>The registration process consists of:
1. Feature detection using ORB on both images
2. Feature matching using brute-force Hamming distance
3. Affine transformation estimation using RANSAC
4. Image transformation using the estimated parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>registration_max_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>default=10000</em>) – Maximum number of features to detect in each image using ORB.
Higher values can improve registration accuracy but increase computation time.</p></li>
<li><p><strong>registration_percentile</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>default=0.9</em>) – Percentile of features to keep after sorting by match quality (0-1).
Only the top percentile of matches by distance are used for transformation
estimation, which helps remove outliers.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="twocan.RegEstimator.M_">
<span class="sig-name descname"><span class="pre">M_</span></span><a class="headerlink" href="#twocan.RegEstimator.M_" title="Link to this definition"></a></dt>
<dd><p>The estimated 2x3 affine transformation matrix after fitting.
Shape is (2, 3) representing the transformation [R|t] where R is
rotation/scaling and t is translation.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="twocan.RegEstimator.y_shape_">
<span class="sig-name descname"><span class="pre">y_shape_</span></span><a class="headerlink" href="#twocan.RegEstimator.y_shape_" title="Link to this definition"></a></dt>
<dd><p>Shape (height, width) of the target image used during fitting.
Used as the default output shape for transformations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a>]</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>The estimator automatically converts input images to 8-bit grayscale for
feature detection using the stretch_255 utility function. This ensures
consistent feature detection regardless of input image dynamic range.</p>
<p>The partial affine transformation model allows rotation, scaling, and
translation but not shearing, which is appropriate for most microscopy
registration tasks where imaging geometry is approximately preserved.</p>
<p>For best results:
- Ensure sufficient overlap between images
- Use images with distinct features (not uniform regions)
- Consider preprocessing to enhance relevant structures
- Adjust max_features based on image complexity and computational budget</p>
<dl class="py method">
<dt class="sig sig-object py" id="twocan.RegEstimator.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.2)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.2)"><span class="pre">ndarray</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../index.html#twocan.RegEstimator" title="twocan.base.RegEstimator"><span class="pre">RegEstimator</span></a></span></span><a class="reference internal" href="../../_modules/twocan/base.html#RegEstimator.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#twocan.RegEstimator.fit" title="Link to this definition"></a></dt>
<dd><p>Estimate the affine transformation matrix between source (X) and target (y) images.</p>
<p>This method detects features in both images using ORB, matches them, and
estimates the best affine transformation that maps source features to
target features using OpenCV’s robust estimation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>np.ndarray</em>) – Source image to be registered. Shape can be (H, W) for single-channel
or (C, H, W) for multi-channel. If multi-channel, all channels are
summed for feature detection.</p></li>
<li><p><strong>y</strong> (<em>np.ndarray</em>) – Target (reference) image to register to. Shape can be (H, W) for
single-channel or (C, H, W) for multi-channel. If multi-channel,
all channels are summed for feature detection.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>self</strong> – The fitted estimator with estimated transformation matrix in <code class="docutils literal notranslate"><span class="pre">self.M_</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../index.html#twocan.RegEstimator" title="twocan.RegEstimator">RegEstimator</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>cv2.error</strong> – If affine transformation cannot be estimated, typically due to
    insufficient or poorly matched features.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The fitting process:
1. Convert images to 8-bit for ORB compatibility
2. Detect up to max_features keypoints in each image
3. Compute ORB descriptors for each keypoint
4. Match descriptors using brute-force Hamming distance
5. Keep top percentile of matches by distance
6. Estimate partial affine transformation using RANSAC</p>
<p>The method uses OpenCV’s estimateAffinePartial2D which finds the optimal
similarity transformation (rotation, scaling, translation) rather than
a full affine transformation. This is more robust for most registration
scenarios.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="twocan.RegEstimator.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.2)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.2)"><span class="pre">ndarray</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.2)"><span class="pre">ndarray</span></a></span></span><a class="reference internal" href="../../_modules/twocan/base.html#RegEstimator.fit_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#twocan.RegEstimator.fit_transform" title="Link to this definition"></a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>This convenience method combines fitting and transformation in a single
call. It’s equivalent to calling fit(X, y).transform(X, y) but slightly
more efficient.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>np.ndarray</em>) – Source image to fit the transformation to and then transform.</p></li>
<li><p><strong>y</strong> (<em>np.ndarray</em>) – Target image to fit the transformation against. This image will
also be included in the output stack.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Stacked array containing the transformed X channels followed by
the original y channels. Shape is (C_x + C_y, H_y, W_y) where
C_x, C_y are the channel counts and H_y, W_y are target dimensions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="twocan.RegEstimator.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.2)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.2)"><span class="pre">ndarray</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../_modules/twocan/base.html#RegEstimator.score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#twocan.RegEstimator.score" title="Link to this definition"></a></dt>
<dd><p>Calculate registration quality metrics between source and target images.</p>
<p>This method computes various metrics to assess the quality of registration
between binary or continuous-valued images. Metrics are calculated only
in regions where both images have valid data after transformation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source</strong> (<em>np.ndarray</em>) – Source image, shape (H, W). Should be the same image used for fitting
or a similar image from the same modality.</p></li>
<li><p><strong>target</strong> (<em>np.ndarray</em>) – Target image, shape (H, W). Should be the same image used for fitting
or a similar image from the same modality.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>Dictionary containing registration quality metrics:</p>
<ul class="simple">
<li><dl class="simple">
<dt>’and’<span class="classifier">float</span></dt><dd><p>Count of pixels where both source and target are positive
(logical AND operation). Higher values indicate better overlap.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’or’<span class="classifier">float</span></dt><dd><p>Count of pixels where either source or target is positive
(logical OR operation).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’xor’<span class="classifier">float</span></dt><dd><p>Count of pixels where source and target disagree
(logical XOR operation). Lower values indicate better agreement.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’iou’<span class="classifier">float</span></dt><dd><p>Intersection over Union ratio (and/or). Values range from 0-1
with 1 indicating perfect overlap. Returns 0.0 if no positive pixels exist.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’source_sum’<span class="classifier">float</span></dt><dd><p>Sum of all source pixel intensities in the overlap region.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>’target_sum’<span class="classifier">float</span></dt><dd><p>Sum of all target pixel intensities in the overlap region.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dict[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a>]</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Metrics are computed only in the intersection region where both images
have valid data after transformation. This ensures fair comparison and
avoids edge effects from the transformation.</p>
<p>For binary images, the metrics have intuitive interpretations:
- IoU is the standard Jaccard index
- ‘and’ counts overlapping positive pixels
- ‘xor’ counts disagreement pixels</p>
<p>For continuous images, the logical operations are applied after
implicit conversion to boolean (non-zero values are True).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="twocan.RegEstimator.set_score_request">
<span class="sig-name descname"><span class="pre">set_score_request</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../index.html#twocan.RegEstimator" title="twocan.base.RegEstimator"><span class="pre">RegEstimator</span></a></span></span><a class="headerlink" href="#twocan.RegEstimator.set_score_request" title="Link to this definition"></a></dt>
<dd><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">score</span></code> method.</p>
<p>Note that this method is only relevant if
<code class="docutils literal notranslate"><span class="pre">enable_metadata_routing=True</span></code> (see <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.set_config.html#sklearn.set_config" title="(in scikit-learn v1.6)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.set_config()</span></code></a>).
Please see <a class="reference external" href="https://scikit-learn.org/stable/metadata_routing.html#metadata-routing" title="(in scikit-learn v1.6)"><span class="xref std std-ref">User Guide</span></a> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">True</span></code>: metadata is requested, and passed to <code class="docutils literal notranslate"><span class="pre">score</span></code> if provided. The request is ignored if metadata is not provided.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">False</span></code>: metadata is not requested and the meta-estimator will not pass it to <code class="docutils literal notranslate"><span class="pre">score</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">str</span></code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p></li>
</ul>
<p>The default (<code class="docutils literal notranslate"><span class="pre">sklearn.utils.metadata_routing.UNCHANGED</span></code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.3.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="(in scikit-learn v1.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>. Otherwise it has no effect.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>True</em><em>, </em><em>False</em><em>, or </em><em>None</em><em>,                     </em><em>default=sklearn.utils.metadata_routing.UNCHANGED</em>) – Metadata routing for <code class="docutils literal notranslate"><span class="pre">source</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">score</span></code>.</p></li>
<li><p><strong>target</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>True</em><em>, </em><em>False</em><em>, or </em><em>None</em><em>,                     </em><em>default=sklearn.utils.metadata_routing.UNCHANGED</em>) – Metadata routing for <code class="docutils literal notranslate"><span class="pre">target</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">score</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>self</strong> – The updated object.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)">object</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="twocan.RegEstimator.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.2)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.2)"><span class="pre">ndarray</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.2)"><span class="pre">ndarray</span></a></span></span><a class="reference internal" href="../../_modules/twocan/base.html#RegEstimator.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#twocan.RegEstimator.transform" title="Link to this definition"></a></dt>
<dd><p>Apply the estimated transformation to the source image(s).</p>
<p>This method transforms the source image(s) using the affine transformation
estimated during fitting. Optionally, a target image can be provided which
will be stacked with the transformed source without transformation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>np.ndarray</em>) – Source image(s) to transform. Shape can be (H, W) for single-channel
or (C, H, W) for multi-channel. All channels are transformed using
the same transformation matrix.</p></li>
<li><p><strong>y</strong> (<em>Optional</em><em>[</em><em>np.ndarray</em><em>]</em><em>, </em><em>default=None</em>) – Target image to stack with transformed source. If provided, this image
is NOT transformed but is included in the output for direct comparison.
Shape should be (H, W) or (C, H, W).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Transformed image(s). If y is None, returns transformed X with shape
(C, H_out, W_out) where H_out, W_out match the target image from fitting.
If y is provided, returns stacked array with transformed X channels
followed by untransformed y channels.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>NotFittedError</strong> – If transform is called before fitting the estimator.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#AssertionError" title="(in Python v3.13)"><strong>AssertionError</strong></a> – If the stored transformation matrix has invalid shape.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The transformation uses scikit-image’s warp function with the inverse
transformation matrix. This ensures proper interpolation and handles
edge cases automatically.</p>
<p>Output image dimensions match the target image used during fitting
unless a different y image is provided during transformation.</p>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="API Reference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="twocan.IFProcessor.html" class="btn btn-neutral float-right" title="twocan.IFProcessor" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Caitlin F. Harrigan.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>